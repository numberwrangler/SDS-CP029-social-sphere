{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "import mlflow.sklearn\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset\n",
    "df = pd.read_csv('../data/ssma.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    # Dropping Student ID as it is not required\n",
    "    df = df.drop(columns=['Student ID'], errors='ignore')\n",
    "    \n",
    "    # Encode binary categorical variables\n",
    "    df['Gender'] = df['Gender'].map({'Male': 0, 'Female': 1})\n",
    "    df['Affects_Academic_Performance'] = df['Affects_Academic_Performance'].map({'Yes': 1, 'No': 0})\n",
    "    \n",
    "    # List of categorical variables for one-hot encoding\n",
    "    categorical_vars = ['Academic_Level', 'Country', 'Most_Used_Platform', 'Relationship_Status']\n",
    "    \n",
    "    # Numerical variables\n",
    "    numerical_vars = [\n",
    "        'Age', 'Avg_Daily_Usage_Hours', 'Sleep_Hours_Per_Night', 'Mental_Health_Score'\n",
    "    ]\n",
    "    \n",
    "    # Defining transformers\n",
    "    numeric_transformer = StandardScaler()\n",
    "    categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "    \n",
    "    # Preprocessing pipeline\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numerical_vars),\n",
    "            ('cat', categorical_transformer, categorical_vars)\n",
    "        ])\n",
    "    \n",
    "    X = df.drop(columns=['Conflicts_Over_Social_Media', 'Addicted_Score'])\n",
    "    y_conflict = df['Conflicts_Over_Social_Media']\n",
    "    y_addiction = df['Addicted_Score']\n",
    "    \n",
    "    X_processed = preprocessor.fit_transform(X)\n",
    "    \n",
    "    return X_processed, y_conflict, y_addiction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_processed, y_conflict, y_addiction = preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y_addiction, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_dict(y_true, y_pred):\n",
    "    return {\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "        \"MSE\": mean_squared_error(y_true, y_pred),\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        \"R2\": r2_score(y_true, y_pred)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1: Training basic LinearRegression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "y_pred_lin_reg = lin_reg.predict(X_test)\n",
    "#print(report_dict(y_test, y_pred_lin_reg))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2: Training RandomForest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_reg = RandomForestRegressor(n_estimators = 10, random_state = 0) \n",
    "rf_reg.fit(X_train, y_train)\n",
    "y_pred_rf_reg = rf_reg.predict(X_test)\n",
    "#print(report_dict(y_test, y_pred_rf_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3: Training XGBoost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_reg = XGBRegressor(max_depth = 2, learning_rate = 0.1, n_estimators = 100)\n",
    "xgb_reg.fit(X_train, y_train)\n",
    "y_pred_xgb_reg = xgb_reg.predict(X_test)\n",
    "#print(report_dict(y_test, y_pred_xgb_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 4: Training SVR Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "# Create pipeline (scaling is important for SVR)\n",
    "pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler(with_mean=False)),\n",
    "    (\"svr\", SVR(kernel='rbf', C=1.0, epsilon=0.2))\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred_svr_reg = pipeline.predict(X_test)\n",
    "#print(report_dict(y_test, y_pred_svr_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking  Experiments Using MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "\n",
    "# setting up the different models for the experiments\n",
    "models = [\n",
    "    (\n",
    "        \"Linear Regression\", \n",
    "        LinearRegression(), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test)\n",
    "    ),\n",
    "    (\n",
    "        \"Random Forest\", \n",
    "        RandomForestRegressor(n_estimators = 10, random_state = 0), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test)\n",
    "    ),\n",
    "    (\n",
    "        \"XGBoost\",\n",
    "        XGBRegressor(max_depth = 2, learning_rate = 0.1, n_estimators = 100), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test)\n",
    "    ),\n",
    "    (\n",
    "        \"SVR\",\n",
    "        SVR(kernel = 'rbf'),\n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test)\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = []\n",
    "\n",
    "for model_name, model, train_set, test_set in models:\n",
    "    X_train = train_set[0]\n",
    "    y_train = train_set[1]\n",
    "    X_test = test_set[0]\n",
    "    y_test = test_set[1]\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    report = report_dict(y_test, y_pred)\n",
    "    reports.append(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/20 19:33:21 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/07/20 19:33:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Linear Regression at: http://127.0.0.1:5000/#/experiments/563191459344469872/runs/b5e9f3320b4740458d32e0a571e22932\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/563191459344469872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/20 19:33:30 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/07/20 19:33:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Random Forest at: http://127.0.0.1:5000/#/experiments/563191459344469872/runs/7b44dbbc09734b37be1d23ae8cf0f2fd\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/563191459344469872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/20 19:33:35 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "c:\\Users\\kola_\\Documents\\projects\\SDS-CP029-social-sphere\\.venv\\Lib\\site-packages\\xgboost\\sklearn.py:1028: UserWarning: [19:33:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\c_api\\c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "2025/07/20 19:33:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run XGBoost at: http://127.0.0.1:5000/#/experiments/563191459344469872/runs/75b7b4eb7116473f9806de9110655721\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/563191459344469872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/20 19:33:41 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/07/20 19:33:46 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run SVR at: http://127.0.0.1:5000/#/experiments/563191459344469872/runs/69379c4832bc49ca8c2f3649277cd92f\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/563191459344469872\n"
     ]
    }
   ],
   "source": [
    "# Initializing MLflow\n",
    "\n",
    "mlflow.end_run()\n",
    "\n",
    "mlflow.set_experiment(\"addiction_level_regressor_v2\")\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000/\")\n",
    "\n",
    "def adjusted_r2_score(y_true, y_pred, n_features):\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    n = len(y_true)\n",
    "    return 1 - (1 - r2) * (n - 1) / (n - n_features - 1)\n",
    "\n",
    "def regression_accuracy(y_true, y_pred, tolerance=0.1):\n",
    "    return np.mean(np.abs(y_true - y_pred) <= tolerance)\n",
    "\n",
    "for i, element in enumerate(models):\n",
    "    model_name = element[0]\n",
    "    model = element[1]\n",
    "    X_test = element[3][0]\n",
    "    y_test = element[3][1]\n",
    "    y_pred = model.predict(X_test)\n",
    "    report = report_dict(y_test, y_pred)\n",
    "    n_features = X_test.shape[1] if hasattr(X_test, 'shape') else X_test.shape[0]\n",
    "    adj_r2 = adjusted_r2_score(y_test, y_pred, n_features)\n",
    "    acc_01 = regression_accuracy(y_test, y_pred, 0.1)\n",
    "    acc_05 = regression_accuracy(y_test, y_pred, 0.5)\n",
    "    \n",
    "    with mlflow.start_run(run_name=model_name):        \n",
    "        mlflow.log_param(\"model\", model_name)\n",
    "        mlflow.log_metric('MAE', report[\"MAE\"])\n",
    "        mlflow.log_metric('MSE', report[\"MSE\"])\n",
    "        mlflow.log_metric('RMSE', report[\"RMSE\"])\n",
    "        mlflow.log_metric('R¬≤', report[\"R2\"])\n",
    "        mlflow.log_metric('Adjusted_R¬≤', adj_r2)\n",
    "        mlflow.log_metric('Accuracy_within_0.1', acc_01)\n",
    "        mlflow.log_metric('Accuracy_within_0.5', acc_05)\n",
    "        \n",
    "         # Use model-specific artifact names\n",
    "        if \"XGB\" in model_name:\n",
    "            mlflow.xgboost.log_model(model, f\"{model_name.lower().replace(' ', '_')}_model\")\n",
    "        else:\n",
    "            mlflow.sklearn.log_model(model, f\"{model_name.lower().replace(' ', '_')}_model\")\n",
    "\n",
    "        # # Register model in registry for all models\n",
    "        # try:\n",
    "        #     run_id = mlflow.active_run().info.run_id\n",
    "        #     model_uri = f\"runs:/{run_id}/model\"\n",
    "        #     mlflow.register_model(model_uri, \"addiction_level_ regressor\")\n",
    "        #     print(f\"‚úÖ Successfully registered {model_name} model\")\n",
    "        # except Exception as e:\n",
    "        #  print(f\"‚ö†Ô∏è  Warning: Could not register {model_name} model: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compairing the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Model Performance Comparison:\n",
      "==================================================\n",
      "            Model  R¬≤ Score     RMSE      MAE\n",
      "    Random Forest  0.984939 0.194608 0.068085\n",
      "              SVR  0.975717 0.247106 0.148652\n",
      "          XGBoost  0.970424 0.272711 0.188535\n",
      "Linear Regression  0.949345 0.356896 0.247683\n",
      "\n",
      "üèÜ Best Performing Model: Random Forest\n",
      "   R¬≤ Score: 0.9849\n",
      "   RMSE: 0.1946\n"
     ]
    }
   ],
   "source": [
    "# Compare all models\n",
    "print(\"üìä Model Performance Comparison:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "comparison_data = []\n",
    "for i, element in enumerate(models):\n",
    "    model_name = element[0]\n",
    "    model = element[1]\n",
    "    X_test = element[3][0]\n",
    "    y_test = element[3][1]\n",
    "    y_pred = model.predict(X_test)\n",
    "    report = report_dict(y_test, y_pred)\n",
    "    \n",
    "    comparison_data.append({\n",
    "        'Model': model_name,\n",
    "        'R¬≤ Score': report['R2'],\n",
    "        'RMSE': report['RMSE'],\n",
    "        'MAE': report['MAE']\n",
    "    })\n",
    "\n",
    "# Create comparison dataframe\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df = comparison_df.sort_values('R¬≤ Score', ascending=False)\n",
    "\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Find best model\n",
    "best_model = comparison_df.iloc[0]\n",
    "print(f\"\\nüèÜ Best Performing Model: {best_model['Model']}\")\n",
    "print(f\"   R¬≤ Score: {best_model['R¬≤ Score']:.4f}\")\n",
    "print(f\"   RMSE: {best_model['RMSE']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
